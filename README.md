# ğŸš€ Local AI Agent with RAG & LangChain

## **Overview**
This project implements a **Retrieval-Augmented Generation (RAG)** system using **Llama 3.2** via **Ollama**. The AI agent is designed to extract precise answers from a **custom dataset** containing customer reviews for a restaurant. By integrating **LangChain**, the model efficiently retrieves relevant context before generating responses, ensuring accurate and context-aware outputs.

## **ğŸ› ï¸ Features**
- **ğŸ” RAG-based Query Handling**: Uses **vector embeddings** to fetch relevant information before generating responses.
- **ğŸ“– Custom Dataset Integration**: Extracts insights from a structured dataset of restaurant customer reviews.
- **ğŸ§  Llama 3.2 via Ollama**: Efficiently processes user queries with optimized response generation.
- **âš¡ Fast and Local Execution**: No external API callsâ€”everything runs locally for **privacy and speed**.
- **ğŸ›  LangChain-powered Retrieval**: Enhances response accuracy by selecting the most relevant context.
- **ğŸŒ Streamlit Web Interface**: Provides a **user-friendly** web UI for interaction.

## **ğŸš€ Installation & Setup**
### **1ï¸âƒ£ Prerequisites**
- **Python 3.8+**
- **Ollama installed** ([Installation Guide](https://ollama.com))
- **Required Python libraries**

### **2ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/yourusername/local-ai-agent.git
cd local-ai-agent
```

### **3ï¸âƒ£ Create a Virtual Environment**
```bash
python -m venv venv
source venv/bin/activate  # macOS/Linux
venv\Scripts\activate     # Windows
```

### **4ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **5ï¸âƒ£ Run the AI Agent in Terminal**
```bash
python main.py
```

### **6ï¸âƒ£ Run the AI Agent on Streamlit**
```bash
streamlit run app.py
```
This will launch a **web-based UI** on `localhost` where users can interact with the AI agent.

## **ğŸ’¡ How It Works**
1. **User Inputs Query** â†’ Enters a restaurant-related question.
2. **Vector Search (RAG)** â†’ Retrieves relevant customer reviews from the dataset.
3. **Llama 3.2 Processes Input** â†’ Generates an accurate response based on retrieved context.
4. **Response Displayed** â†’ The AI agent provides an insightful answer.
5. **Streamlit Web Interface** â†’ Users can interact via a web-based UI.


## **ğŸ¯ Future Enhancements**
- âœ… Improved ranking for retrieved documents
- âœ… Support for additional datasets
- âœ… Cloud deployment for remote access

## **ğŸ¤ Contributing**
Contributions are welcome! Feel free to **fork** this repo, submit PRs, or suggest improvements. ğŸš€

## **ğŸ“œ License**
This project is open-source under the **MIT License**.
